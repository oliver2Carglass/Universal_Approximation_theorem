# Universal_Approximation_theorem
Universal Approximation Theorem  states that a neural network with two layers (i.e., one hidden layer and one output layer), given enough neurons in the hidden layer and appropriate activation functions, can approximate any continuous function on a compact domain to an arbitrary level of precision.
