# Universal_Approximation_theorem
Universal Approximation Theorem  states that a neural network with two layers (i.e., one hidden layer and one output layer), given enough neurons in the hidden layer and appropriate activation functions, can approximate any continuous function on a compact domain to an arbitrary level of precision.

---

**What is this ?**:

My work aim to try and apply the Universal approcimation theorem. At the very beginijng you can set up your own variable for the f function and see how the model progressively fit it, you can also try with differents neurons.
It's most like a sand box than a project.

**Why should I try ?** : 

It's so satisfying ^^